import numpy as np
from custom_taxi_env import CustomTaxiEnv
import pygame
import time
import os

def run_trained_taxi(q_table_path="q_table.npy", delay=0.3, max_episodes=None):
    """
    EÄŸitilmiÅŸ Q-table ile taksiyi Ã§alÄ±ÅŸtÄ±r
    
    Args:
        q_table_path: Q-table dosya yolu
        delay: Her adÄ±m arasÄ±ndaki bekleme sÃ¼resi (saniye)
        max_episodes: Maksimum gÃ¶rev sayÄ±sÄ± (None = sonsuz)
    """
    
    # Q-table'Ä± yÃ¼kle
    if not os.path.exists(q_table_path):
        print(f"HATA: {q_table_path} bulunamadÄ±!")
        print("Ã–nce 'python train_qtable.py' ile eÄŸitim yapÄ±n.")
        return
    
    Q = np.load(q_table_path)
    print(f"âœ“ Q-table yÃ¼klendi: {q_table_path}")
    print(f"  Q-table boyutu: {Q.shape}")
    print(f"  Toplam Ã¶ÄŸrenilen state sayÄ±sÄ±: {np.count_nonzero(Q)}")
    
    env = CustomTaxiEnv()
    
    print("\n" + "=" * 60)
    print("OTONOM TAKSÄ° Ã‡ALIÅIYOR")
    print("=" * 60)
    print("Pencereyi kapatarak Ã§Ä±kabilirsiniz.")
    print("=" * 60 + "\n")
    
    episode = 0
    total_rewards = []
    total_steps = []
    
    try:
        # Ä°lk gÃ¶rev
        state, _ = env.reset()
        env.render()
        
        while True:
            episode += 1
            done = False
            step_count = 0
            episode_reward = 0
            
            print(f"\nğŸš– GÃ¶rev #{episode} baÅŸladÄ±")
            print(f"   Yolcu: ({env.pass_row}, {env.pass_col})")
            print(f"   Hedef: ({env.dest_row}, {env.dest_col})")
            
            # Tek gÃ¶rev dÃ¶ngÃ¼sÃ¼
            while not done:
                # Event kontrolÃ¼ (pencere kapatma)
                for event in pygame.event.get():
                    if event.type == pygame.QUIT:
                        raise KeyboardInterrupt
                
                # En iyi aksiyonu seÃ§ (exploitation only, no exploration)
                action = np.argmax(Q[state])
                
                # AdÄ±m at
                state, reward, done, _, info = env.step(action)
                episode_reward += reward
                step_count += 1
                
                # GÃ¶rselleÅŸtir
                env.render()
                time.sleep(delay)
                
                # Sonsuz dÃ¶ngÃ¼ kontrolÃ¼
                if step_count > 30:
                    print("   âš ï¸  Ã‡ok uzun sÃ¼rdÃ¼, yeni gÃ¶rev baÅŸlatÄ±lÄ±yor...")
                    break
            
            # GÃ¶rev tamamlandÄ±
            total_rewards.append(episode_reward)
            total_steps.append(step_count)
            
            if done and episode_reward > 0:
                print(f"   âœ“ GÃ¶rev tamamlandÄ±!")
            else:
                print(f"   âœ— GÃ¶rev baÅŸarÄ±sÄ±z")
            
            print(f"   AdÄ±m sayÄ±sÄ±: {step_count}")
            print(f"   Toplam Ã¶dÃ¼l: {episode_reward:.1f}")
            
            # Ä°statistikler
            if episode % 5 == 0:
                avg_reward = np.mean(total_rewards[-5:])
                avg_steps = np.mean(total_steps[-5:])
                success_rate = sum(1 for r in total_rewards[-5:] if r > 0) / 5 * 100
                print(f"\nğŸ“Š Son 5 gÃ¶rev istatistikleri:")
                print(f"   Ortalama Ã¶dÃ¼l: {avg_reward:.1f}")
                print(f"   Ortalama adÄ±m: {avg_steps:.1f}")
                print(f"   BaÅŸarÄ± oranÄ±: {success_rate:.0f}%")
            
            # Maksimum episode kontrolÃ¼
            if max_episodes and episode >= max_episodes:
                print(f"\nâœ“ {max_episodes} gÃ¶rev tamamlandÄ±, program sonlandÄ±rÄ±lÄ±yor.")
                break
            
            # Yeni yolcu Ã¼ret (TAKSÄ° AYNI YERDE KALIR)
            print(f"   âŸ³ Yeni yolcu Ã¼retiliyor (taksi aynÄ± yerde)...")
            time.sleep(0.5)
            state, _ = env.reset_passenger()  # Sadece yolcu deÄŸiÅŸir, taksi kalmaz
            env.render()
            time.sleep(0.5)
    
    except KeyboardInterrupt:
        print("\n\nâ¸ Program durduruldu.")
    
    finally:
        # Final istatistikleri
        if total_rewards:
            print("\n" + "=" * 60)
            print("FINAL Ä°STATÄ°STÄ°KLER")
            print("=" * 60)
            print(f"Toplam gÃ¶rev: {len(total_rewards)}")
            print(f"Ortalama Ã¶dÃ¼l: {np.mean(total_rewards):.2f}")
            print(f"Ortalama adÄ±m: {np.mean(total_steps):.1f}")
            success_count = sum(1 for r in total_rewards if r > 0)
            print(f"BaÅŸarÄ±lÄ± gÃ¶rev: {success_count}/{len(total_rewards)} ({success_count/len(total_rewards)*100:.1f}%)")
            print(f"En iyi Ã¶dÃ¼l: {max(total_rewards):.1f}")
            print(f"En kÃ¶tÃ¼ Ã¶dÃ¼l: {min(total_rewards):.1f}")
            print("=" * 60)
        
        env.close()
        print("\nâœ“ Program sonlandÄ±.")


if __name__ == "__main__":
    # FarklÄ± kullanÄ±m Ã¶rnekleri:
    
    # 1. Normal kullanÄ±m (sonsuz)
    run_trained_taxi(delay=0.2)
    
    # 2. Belirli sayÄ±da gÃ¶rev
    # run_trained_taxi(delay=0.2, max_episodes=10)
    
    # 3. Daha hÄ±zlÄ± (kÄ±sa bekleme)
    # run_trained_taxi(delay=0.1)
    
    # 4. Daha yavaÅŸ (detaylÄ± izleme)
    # run_trained_taxi(delay=0.5)
    
    # 5. Ã–zel Q-table dosyasÄ±
    # run_trained_taxi(q_table_path="q_table_20241128_143000.npy", delay=0.2)
